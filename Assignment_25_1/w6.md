# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `3부. 데이터 분석하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_6th_TIL

### 3부. 데이터 분석하기
### 12.통계 기반 분석 방법론



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | ✅      | 
|7주차| 3부 p.357~615  | 🍽️      |

<!-- 여기까진 그대로 둬 주세요-->

# 12.통계 기반 분석 방법론

```
✅ 학습 목표 :
* 주성분 분석(PCA)의 개념을 설명할 수 있다.
* 다중공선성을 진단할 수 있다.
* Z-TEST와 T-TEST의 개념을 비교하고, 적절한 상황에서 검정을 설계하고 수행할 수 있다.
* ANOVA TEST를 활용하여 세 개 이상의 그룹 간 평균 차이를 검정하고, 사후검정을 수행할 수 있다.
* 카이제곱 검정을 통해 범주형 변수 간의 독립성과 연관성을 분석하는 방법을 설명할 수 있다.
```

## 12.1. 분석 모델 개요

>### 1. 통계 모델 vs 기계 학습

데이터 분석 방법론은 크게 두 가지로 나뉜다.
바로 **통계학 기반의 통계 모델**과 인공지능에서 발전된 **기계 학습(Machine Learning)**이다.

| 통계 모델                | 기계 학습             |
| -------------------- | ----------------- |
| **모형화와 해석**을 중요하게 여김 | **예측 정확도 향상**에 중점 |
| 오차와 불확실성 추정을 강조      | 대용량 데이터를 기반으로 학습  |
| 해석 중심의 학문            | 성능 중심의 응용 기술      |
| 경제학적 모델링에 가까움        | 비즈니스 예측과 최적화에 강점  |

기계 학습은 통계 모델에서 출발한 개념이 많으며, 실제로 통계 모델을 이해하고 있으면 기계 학습 모델도 보다 잘 활용할 수 있다.

---

>### 2. 전통적 통계 이론 기반 분석

전통 통계 방법론은 이미 앞서 다룬 기초적 통계 이론(분포, 추정, 검정)을 기반으로 하며, 이 장에서는 다양한 변수 유형 간의 관계 분석을 중심으로 한다.

* 한 변수의 분포 → 기술통계
* 두 변수 간 관계 → 교차분석, 상관분석, 회귀분석
* 집단 간 비교 → 가설검정, 분산분석

이는 모두 통계적 가설 설정, 오차 추정, 해석을 동반하며 분석 목적은 '설명력'에 가깝다.

---

>### 3. 데이터 분석 방법론 개요

#### 📌 통계 모델 기반 분석

| 독립변수 | 종속변수 | 분석 방법론            | 용도     |
| ---- | ---- | ----------------- | ------ |
| 질적   | 질적   | 교차분석, 스피어만 서열상관분석 | 연관성 분석 |
| 질적   | 양적   | Z-test, T-test    | 가설 검정  |
| 양적   | 질적   | ANOVA, MANOVA     | 분산 분석  |
| 양적   | 양적   | 피어슨 상관분석          | 연관성 분석 |

---

### 4. 기계 학습 기반 분석

기계 학습은 **지도학습, 비지도학습, 강화학습**으로 나뉘며, 종속변수의 유무에 따라 구분된다.


#### 📌 지도학습 (Supervised Learning)

* **정답(Label)**이 있는 데이터를 학습
* 예측 또는 분류 목적

| 독립변수 | 종속변수 | 분석 방법                              | 분석 목적 |
| ---- | ---- | ---------------------------------- | ----- |
| 질적   | 질적   | 로지스틱 회귀, 분류나무, 랜덤포레스트, 나이브베이즈, 신경망 | 분류 분석 |
| 질적   | 양적   | 선형 회귀, 회귀나무, 랜덤포레스트 회귀, 신경망        | 예측 분석 |
| 양적   | 질적   | K-NN, SVM, 판별분석, 신경망 등             | 분류 분석 |
| 양적   | 양적   | 선형 회귀, 랜덤포레스트, 신경망 등               | 예측 분석 |



#### 📌 비지도학습 (Unsupervised Learning)

* **정답이 없는 데이터**에서 패턴을 찾아내는 방식
* 데이터 구조 파악, 군집화, 차원 축소 등

| 분석 기법             | 목적       |
| ----------------- | -------- |
| 주성분분석(PCA), 요인분석  | 차원 축소    |
| K-means, SOM      | 군집 분석    |
| Association Rules | 연관 규칙 도출 |

**예시**: 고객을 소득, 연령, 소비 성향에 따라 군집으로 분류하는 고객 세분화(customer segmentation)



#### 📌 강화학습 (Reinforcement Learning)

* **보상과 벌을 통해 학습**하는 방법
* 대표적으로 알파고, 게임 AI, 자율주행 등이 있다.

**핵심 개념**: 시행착오(trial & error)

* A버튼을 누르면 바나나, B버튼은 전기 충격
* 원숭이는 반복을 통해 A버튼만 누르게 됨
* 이렇게 학습되는 방식이 강화학습

| 방식             | 설명            |
| -------------- | ------------- |
| Model-free RL  | 시행착오 기반 직접 학습 |
| Model-based RL | 환경을 모델링한 후 학습 |

---

>### 5. 방법론 선택 기준 요약

* **지도학습**: 정답이 있는 데이터에서 분류·예측이 목적일 때
* **비지도학습**: 정답 없이 군집이나 패턴 발견이 목적일 때
* **강화학습**: 환경과 상호작용하며 보상 최적화를 할 때

또한, **질적/양적 변수의 조합**에 따라 사용할 수 있는 방법론이 달라지며,
하나의 방법이 여러 변수 형태에서 적용 가능한 경우도 존재한다.

예:

* 회귀 모델은 질적, 양적 독립변수 모두 사용 가능
* K-NN은 질적 종속변수 분류, 양적 종속변수 예측 모두에 사용 가능



## 12.2. 주성분 분석(PCA)

>### 1. 개념

주성분 분석(Principal Component Analysis; PCA)은 여러 개의 독립변수를 잘 설명해 줄 수 있는 핵심 성분을 추출하는 차원 축소 기법이다.
PCA는 데이터의 전체 분산을 최대한 보존하는 방향으로 새로운 축을 구성하여, 기존 고차원 데이터를 더 적은 수의 축으로 표현할 수 있게 한다.


#### 차원의 저주 (Curse of Dimensionality)

* 변수의 수(차원)가 많아지면 분석을 위한 최소한의 데이터 수도 증가한다.
* 예측은 불안정해지고, **과적합(Overfitting)** 위험도 증가한다.
* 일반적으로 차원 하나당 30개의 데이터가 필요하다.
* 예: 20개의 변수 → 600개 이상의 데이터 필요


#### 차원 축소 방법

| 방식        | 설명                                           |
| --------- | -------------------------------------------- |
| 변수 선택법    | 비교적 불필요하거나 설명력이 낮은 변수를 제거함                   |
| 잠재 성분 추출법 | 변수 간의 공통된 성분(요인)을 추출하여 변수 수를 줄임 → PCA, CFA 등 |

PCA와 공통요인분석(CFA)은 대표적인 **요인 추출 기반** 차원 축소법이며,
PCA는 정보의 손실을 최소화하는 데 집중하고, CFA는 변수 간 구조 해석에 더 중점을 둔다.



>### 2. PCA의 원리

* PCA는 데이터의 분산을 최대한 보존하는 축을 찾는 과정이다.
* 새로운 축(주성분)은 기존 변수들의 **선형 결합**으로 구성된다.
* 제1주성분은 전체 데이터 분산을 가장 잘 설명하는 축이며,
* 제2주성분은 제1주성분과 **직교(orthogonal)** 하면서 두 번째로 높은 분산을 담는다.


#### 주성분 시각적 설명

* X1, X2 두 변수의 분포를 시각화하면, 분산이 가장 넓게 퍼지는 축이 제1주성분이 된다.
* 각 점에서 주성분 축까지 수직으로 투영한 선들의 길이 제곱합이 분산이다.
* 피타고라스 정리에 따라 이 거리의 제곱합을 최대화하는 축을 찾는 것이 PCA의 핵심이다.

![alt text](../Assignment_25_1/images/스크린샷%202025-05-16%20오후%202.40.20.png)

```math
SS(x_1, x_2, ..., x_n) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}
```

* 설명력이 높은 주성분부터 차례대로 선택하여 변수 수를 축소할 수 있다.
* 대부분의 경우, **제1주성분과 제2주성분만으로 전체 분산의 상당 부분을 설명**한다.



>### 3. 실습 (Glass 데이터셋 기반)

**데이터 전처리 및 정규화**

```python
from sklearn.preprocessing import MinMaxScaler
df1 = df.drop('Type', axis=1) # 종속변수 제거
scaler = MinMaxScaler()
df_minmax = scaler.fit_transform(df1)
```

**PCA 적용**

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=9) # 최대수 9개
df_pca = pca.fit_transform(df_minmax)
```

**설명력 확인**

```python
np.round(pca.explained_variance_ratio_, 3)
```

| 주성분 | 설명력   |
| --- | ----- |
| C1  | 0.454 |
| C2  | 0.180 |
| C3  | 0.126 |
| C4  | 0.098 |
| C5  | 0.069 |
| C6  | 0.042 |
| C7  | 0.026 |
| C8  | 0.004 |
| C9  | 0.000 |

→ 총합: 100% (9개 축으로 전체 분산을 모두 설명)

**2개 축만 사용하여 시각화용 차원 축소**

```python
pca = PCA(n_components=2)
df_pca = pca.fit_transform(df_minmax)
df_pca = pd.DataFrame(df_pca, columns=['C1', 'C2'])
```

**Type 정보 결합 및 시각화**

```python
df_concat = pd.concat([df_pca, df[['Type']]], axis=1)
sns.scatterplot(data=df_concat, x='C1', y='C2', hue='Type')
```

* 전체 설명력: 약 63% (C1 + C2)
* 주성분 상에서 데이터 간 군집(클래스) 분리 여부를 시각적으로 확인 가능

---

#### 해석 및 유의점

* 주성분 분석은 **데이터 압축**, **시각화**, **모델 성능 향상** 등에 유용
* 모든 변수 간 상관관계가 높거나 다중공선성이 존재할 때 특히 효과적
* 변수 스케일이 다르면 분산 크기에 영향을 주기 때문에 **정규화 or 표준화 선행 필수**
* 단점: 각 주성분은 해석 가능한 변수 이름이 없으며, 해석력이 떨어질 수 있음




## 12.4. 다중공선성 해결과 섀플리 밸류 분석

아래는 업로드한 이미지들을 바탕으로 정리한 **12.4 다중공선성 해결과 샤플리 밸류 분석** 마크다운 형식 요약입니다.

---

## 12.4. 다중공선성 해결과 샤플리 밸류 분석

> ### 1. 개념

다중공선성(Multicollinearity)이란 두 개 이상의 독립변수 간에 높은 상관관계가 존재하여, 선형 회귀 분석에서 변수들이 서로 독립적이라는 가정을 위배하는 상황을 의미한다.

* 회귀분석에서 다중공선성이 발생하면 추정치의 통계적 유의성이 낮아지며, 회귀계수의 해석이 어려워지고 모델의 적합성도 저하된다.
* 예: 교통사고 예측 변수로 ‘마신 소주의 양’과 ‘혈중알코올농도’를 동시에 포함하면 둘 사이의 높은 상관관계로 인해 문제 발생
![alt](../Assignment_25_1/images/스크린샷%202025-05-16%20오후%202.47.20.png)
---

> ### 2. 샤플리 밸류(Shapley Value)를 통한 변수 중요도 측정

샤플리 밸류는 각 변수의 **설명력 기여도**를 공정하게 평가하기 위한 방식으로, 모든 가능한 변수 조합에서 해당 변수가 기여한 정도를 평균하여 산출한다.

#### 계산 예시 (x₁, x₂, x₃ 조합)

| 조합               | x₁의 기여도    |
| ---------------- | ---------- |
| x₁ 단독            | 0.15       |
| x₁, x₂ or x₁, x₃ | 0.115 (평균) |
| x₁, x₂, x₃ 전체 포함 | 0.04       |

→ x₁의 샤플리 밸류 = (0.15 + 0.115 + 0.04) / 3 = **0.101**

다른 변수들도 동일 방식으로 산출:

* x₂의 샤플리 밸류 = 0.141
* x₃의 샤플리 밸류 = 0.106
* 총합 = 0.101 + 0.141 + 0.106 = 0.35

샤플리 밸류는 변수의 평균적인 설명력 기여도를 나타내므로, 변수 선택 기준으로 활용 가능하다.

---

> ### 3. 다중공선성 판단 기준

| 판단 기준                           | 설명                                        |
| ------------------------------- | ----------------------------------------- |
| 상관계수 기준                         | 독립변수 간 상관계수의 절댓값이 0.7 이상이면 다중공선성 의심       |
| t-value 기준                      | 회귀계수의 유의성 기준으로 사용 (아래 표 참고)               |
| VIF (Variance Inflation Factor) | 분산팽창계수로, 특정 독립변수가 다른 변수들로부터 얼마나 설명되는지를 평가 |

#### t-value 기준 표

| 절댓값 기준  | 유의수준     |
| ------- | -------- |
| ≥ 2.58  | α = 0.01 |
| ≥ 1.96  | α = 0.05 |
| ≥ 1.645 | α = 0.10 |

t-value가 낮을 경우 해당 독립변수가 중복 설명되었을 가능성이 있음

---

> ### 4. VIF (Variance Inflation Factor)

VIF는 다음과 같이 계산된다:

```math
VIF_k = \\frac{1}{1 - R_k^2}
```

* R\_k²는 k번째 독립변수를 나머지 변수들로 회귀했을 때 결정계수
* 일반적으로:

  * **VIF > 5** → 다중공선성 의심
  * **VIF > 10** → 다중공선성 존재로 판단

예: A 변수의 VIF가 16이면, 해당 변수는 표준오차가 √16 = 4배 증가했음을 의미

---

> ### 5. 다중공선성 해결 방법

| 해결 방법      | 설명                                    |
| ---------- | ------------------------------------- |
| VIF 기준 제거  | VIF 값이 가장 높은 변수 제거 후 다시 VIF 확인        |
| 상관계수 기준 제거 | 상관관계가 높은 변수 중 설명력 낮은 변수 제거            |
| 변수 변환      | 로그, 표준화 등으로 변수 간 상관성 완화               |
| 변수 축소      | PCA 등 차원 축소 기법 활용                     |
| 변수 선택 알고리즘 | 단계적 선택법(Forward/Backward/Stepwise) 사용 |

실무에서는 **PCA를 통해 변수 축소**, **샤플리 밸류로 설명력 평가**,
또는 **알고리즘 기반 변수 선택**이 함께 사용되기도 한다.


## 12.6. Z-test와 T-test

> ### 1. 개념 비교

Z-test와 T-test는 **두 집단 간 평균 차이**를 통계적으로 검정하는 기법이다.
차이는 **모집단 분산(표준편차) 정보를 알고 있는가**에 따라 나뉜다.

| 구분     | 사용 조건                    | 설명                       |
| ------ | ------------------------ | ------------------------ |
| Z-test | 모집단 분산을 알고 있음            | 모집단의 분산 정보를 활용하여 정규분포 가정 |
| T-test | 모집단 분산을 모름 / 표본 크기 30 미만 | 표본에서 계산한 표준편차로 정규분포 추정   |

※ T-test는 일반적으로 표본 크기 ≥ 30일 때도 사용할 수 있음

---

> ### 2. 분류 기준

| 구분     | 분석 목적            | 표본 조건  |
| ------ | ---------------- | ------ |
| Z-test | 단일 집단 평균/비율 검정   | n ≥ 30 |
| T-test | 단일/두 집단 평균/비율 검정 | 제한 없음  |
| ANOVA  | 두 집단 이상 평균/비율 비교 | n ≥ 30 |

---

> ### 3. 단일 집단 평균 T-test 예제

* **목표**: 고객 마케팅 프로그램 도입 전후 매출 평균 차이 유의성 검정
* **가설**:

```text
H0: 전후 평균 매출은 같다
H1: 전후 평균 매출은 다르다
```

* **검정 방식**: 양측검정 (difference ≠ 0)
* **계산식**:

```math
t_{stat} = \frac{\bar{X} - \mu}{S_X / \sqrt{n}}
```

* **해석**:
  t값 1.6, 유의수준 0.05, 자유도 99 → 기각역 ±1.984
  → t값이 기각역에 포함되지 않으므로 귀무가설 채택 (차이 없음)

---

> ### 4. Z-test 개념 정리

Z-test는 모집단의 표준편차(σ)를 알고 있을 때 사용하며, 계산 방식은 T-test와 유사하나 σ를 이용한다.

```math
Z_{stat} = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}}
```

---

> ### 5. 두 집단 평균 차이 검정 (독립표본 T-test)

```math
t_{stat} = \frac{\bar{X}_A - \bar{X}_B}{\sqrt{S_A^2 / n_A + S_B^2 / n_B}}
```

* 두 집단의 평균 차이에 대한 검정
* 모집단 분산을 모를 때 사용
* 귀무가설: 두 집단 평균은 같다
* 유의수준 기준 t값과 비교하여 채택 여부 판단

---

> ### 6. 비율 차이 검정

#### (1) 단일 집단 비율

```math
t_{stat} = \frac{p - \pi}{\sqrt{\pi (1 - \pi) / n}}
```

* 표본 비율 p과 귀무가설 비율 π 차이 검정

#### (2) 두 집단 비율

```math
t_{stat} = \frac{(p_A - p_B) - (\pi_A - \pi_B)}{\sqrt{\frac{p_A(1 - p_A)}{n_A} + \frac{p_B(1 - p_B)}{n_B}}}
```

* 예: 여성 비율 비교 등

---

> ### 7. 정규성 검정

* **Shapiro-Wilk Test** 사용

```python
from scipy.stats import shapiro
print(shapiro(df['컬럼명']))
```

* p-value > 0.05 → 정규성 만족 (PCA 등 분석 가능)

---

> ### 8. 실습 

```python
# 필수 패키지
from scipy.stats import ttest_rel, ttest_ind, shapiro
from statsmodels.stats.weightstats import ztest
import pandas as pd
import seaborn as sns

# 데이터 불러오기
df = pd.read_csv("datasets/Golf_test.csv")

# 정규성 확인
shapiro(df["TypeA_before"])

# Z-test (독립표본)
ztest(df['TypeA_before'], x2=df['TypeB_before'])

# T-test (대응표본)
ttest_rel(df['TypeA_before'], df['TypeA_after'])
```

---

> ### 9. 결과 해석

* p-value < 0.05 → 통계적으로 유의한 차이 존재
* p-value ≥ 0.05 → 귀무가설 채택 (차이 없음)

예:

```python
TtestResult(statistic=1.22, pvalue=0.227) # 유의하지 않음
```


## 12.7. ANOVA

> ### 1. 개념

ANOVA는 **세 집단 이상의 평균 차이 검정**을 위한 통계 기법이다.
두 집단 간 검정에는 T-test가, **세 집단 이상일 경우 ANOVA**가 유리하다.
중복 T-test는 신뢰도(α 수준)를 낮추기 때문에 ANOVA를 사용한다.

> ### 2. 검정 방식

ANOVA는 **F-분포**를 기반으로 한다.

* 집단 간 분산이 크고
* 집단 내 분산이 작을수록
  → 평균 차이가 유의하다고 본다.

**공식 (F-statistic)**

```math
F = \frac{MS_b}{MS_w} = \frac{SS_b / (k - 1)}{SS_w / (n - k)}
```

* $SS_b$: 집단 간 제곱합
* $SS_w$: 집단 내 제곱합
* $MS_b, MS_w$: 평균 제곱합
* $k$: 집단 수, $n$: 전체 관측치 수



> ### 3. 귀무/대립가설

* $H_0$: 모든 집단 평균은 같다
* $H_1$: 적어도 한 집단 평균은 다르다


> ### 4. ANOVA 유형

| 독립변수 수 | 이름            | 예시            |
| ------ | ------------- | ------------- |
| 1개     | One-way ANOVA | 연령대별 SNS 사용시간 |
| 2개     | Two-way ANOVA | 지역 & 성별 효과    |

→ 교차분석과 달리, 연속형 종속변수(특성 값)을 갖는다.



> ### 5. 사후 검정 (Post-hoc Test)

ANOVA에서 유의미한 차이가 있을 경우,
**어느 집단 간에 차이가 있는지**를 확인하는 검정

* Tukey HSD, Scheffe 검정 등 사용

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

posthoc = pairwise_tukeyhsd(df['value'], df['group'], alpha=0.05)
posthoc.plot_simultaneous()
```



> ### 6. ols 이용 실습 코드

```python
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

model = ols('value ~ C(group)', df).fit()
anova_lm(model)
```




## 12.8. 카이제곱 검정(교차분석)


>### 1. 개념

* **카이제곱 검정**은 **두 범주형 변수 간의 독립성(관련성)** 여부를 검정하는 통계 기법이다.
* **명목형, 서열형 변수**에 대해 사용할 수 있으며, 대표적으로 교차표(crosstab)를 활용한다.
* 예: 성별과 제품 사용 여부, 성별과 흡연 여부 등

>### 2. 가설 설정

| 가설 유형          | 내용                         |
| -------------- | -------------------------- |
| **귀무가설 $H_0$** | 두 변수는 서로 관련이 없다 (독립이다)     |
| **대립가설 $H_1$** | 두 변수는 서로 관련이 있다 (상관관계가 있다) |


>### 3. 검정 절차

1. **교차표 생성** (관측빈도 계산)

| 성별  | 있음 | 없음 | 행 합 |
| --- | -- | -- | --- |
| 남성  | 21 | 31 | 52  |
| 여성  | 18 | 30 | 48  |
| 열 합 | 39 | 61 | 100 |
---
2. **기대빈도 계산**

기대빈도 계산식 (각 셀 기준):

$$
E_{ij} = \frac{(행합)_i \times (열합)_j}{전체합}
$$

예시:

* A셀 (남성&있음): $\frac{52 \times 39}{100} = 20.28$
* B셀 (남성&없음): $\frac{52 \times 61}{100} = 31.72$
* C셀 (여성&있음): $\frac{48 \times 39}{100} = 18.72$
* D셀 (여성&없음): $\frac{48 \times 61}{100} = 29.28$

---
3. **카이제곱 통계량 계산**

카이제곱 값 계산식:

$$
\chi^2 = \sum \frac{(관측빈도 - 기대빈도)^2}{기대빈도}
$$

예시:

| 셀      | 계산식                            | 결과         |
| ------ | ------------------------------ | ---------- |
| A      | $\frac{(21 - 20.28)^2}{20.28}$ | 0.0256     |
| B      | $\frac{(31 - 31.72)^2}{31.72}$ | 0.0163     |
| C      | $\frac{(18 - 18.72)^2}{18.72}$ | 0.0277     |
| D      | $\frac{(30 - 29.28)^2}{29.28}$ | 0.0177     |
| **합계** |                                | **0.0873** |

---
4. **자유도(df) 계산 및 유의성 판단**

* 자유도: $(행의 수 - 1) \times (열의 수 - 1) = 1 \times 1 = 1$
* 유의수준 0.05에서의 임계값: **3.84**
* 결론: $\chi^2 = 0.0873 < 3.84$ → **귀무가설 채택** (성별과 제품 사용 여부는 관련 없음)


>### 4. 실습 코드

```python
import scipy.stats
from scipy.stats import chi2_contingency
import pandas as pd
import matplotlib.pyplot as plt

# 데이터 불러오기
df = pd.read_csv("datasets/smoker.csv")

# 교차표 생성
crosstab = pd.crosstab(df.sex, df.smoke)

# 카이제곱 검정
chiresult = chi2_contingency(crosstab, correction=False)
print("Chi square:", chiresult[0])
print("P-value:", chiresult[1])
```

#### 결과 예시

| 변수         | Chi-square 값 | P-value |
| ---------- | ------------ | ------- |
| 성별 × 흡연 여부 | 7.88         | 0.0052  |

→ P-value < 0.05 → **귀무가설 기각** → **성별과 흡연 여부 간 관련성 있음**






<br>
<br>

# 확인 문제

### **문제 1.**
> **🧚 경희는 다트비 교육 연구소의 연구원이다. 경희는 이번에 새롭게 개발한 교육 프로그램이 기존 프로그램보다 학습 성취도 향상에 효과적인지 검증하고자 100명의 학생을 무작위로 두 그룹으로 나누어 한 그룹(A)은 새로운 교육 프로그램을, 다른 그룹(B)은 기존 교육 프로그램을 수강하도록 하였다. 실험을 시작하기 전, 두 그룹(A, B)의 초기 시험 점수 평균을 비교한 결과, 유의미한 차이가 없었다. 8주 후, 학생들의 최종 시험 점수를 수집하여 두 그룹 간 평균 점수를 비교하려고 한다.**   

> **🔍 Q1. 이 실험에서 사용할 적절한 검정 방법은 무엇인가요?**

```
독립표본 T-검정 
```

> **🔍 Q2. 이 실험에서 설정해야 할 귀무가설과 대립가설을 각각 작성하세요.**

```
- 귀무가설(H0): 두 그룹(A, B)의 최종 시험 점수 평균은 같다.
- 대립가설(H1): 두 그룹(A, B)의 최종 시험 점수 평균은 다르다.
```

> **🔍 Q3. 검정을 수행하기 위한 절차를 순서대로 서술하세요.**

<!--P.337의 실습 코드 흐름을 확인하여 데이터를 불러온 후부터 어떤 절차로 검정을 수행해야 하는지 고민해보세요.-->

1. 실험 후 수집된 두 그룹(A, B)의 최종 시험 점수 데이터를 불러온다.
2. 정규성 검정(Shapiro-Wilk Test 등)을 통해 각 그룹의 점수 분포가 정규분포를 따르는지 확인한다.
3. 등분산성 검정(Bartlett 또는 Levene 검정 등)을 통해 두 그룹의 분산이 같은지 확인한다.
4. 등분산성 여부에 따라 T-test 수행
   - 등분산이면 equal variance T-test
   - 등분산이 아니면 Welch's T-test
5. T-test 결과의 p-value를 통해 유의수준(예: 0.05)과 비교하여 귀무가설 기각 여부 판단
```

> **🔍 Q4. 이 검정을 수행할 때 가정해야 하는 통계적 조건을 설명하세요.**

```
1. 두 표본은 서로 독립적이어야 함 (독립표본)
2. 각 표본은 정규분포를 따라야 함 (정규성 가정)
3. 두 집단의 분산은 동일해야 함 (등분산 가정, Welch의 경우 완화 가능)

```

> **🔍 Q5. 추가적으로 최신 AI 기반 교육 프로그램(C)도 도입하여 기존 프로그램(B) 및 새로운 프로그램(A)과 비교하여 성취도 차이가 있는지 평가하고자 한다면 어떤 검정 방법을 사용해야 하나요? 단, 실험을 시작하기 전, C 그룹의 초기 점수 평균도 A, B 그룹과 유의미한 차이가 없었다고 가정한다.**

```
일원 분산분석 (One-way ANOVA)

```

> **🔍 Q6. 5번에서 답한 검정을 수행한 결과, 유의미한 차이가 나타났다면 추가적으로 어떤 검정을 수행해 볼 수 있을까요?**

```
사후 검정 (Post-hoc Test), 예: Tukey의 HSD 검정
```

---

### **문제 2. 카이제곱 검정**  
> **🧚 다음 중 어떠한 경우에 카이제곱 검정을 사용해야 하나요?   
1️⃣ 제품 A, B, C의 평균 매출 차이를 비교하고자 한다.  
2️⃣ 남성과 여성의 신체 건강 점수 평균 차이를 분석한다.  
3️⃣ 제품 구매 여부(구매/미구매)와 고객의 연령대(10대, 20대, 30대…) 간의 연관성을 분석한다.  
4️⃣ 특정 치료법이 환자의 혈압을 감소시키는 효과가 있는지 확인한다.**  

```
3️⃣ 제품 구매 여부(구매/미구매)와 고객의 연령대(10대, 20대, 30대…) 간의 연관성을 분석한다.
```

### 🎉 수고하셨습니다.