# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `3부. 데이터 분석하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_6th_TIL

### 3부. 데이터 분석하기
### 12.통계 기반 분석 방법론



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | ✅      | 
|7주차| 3부 p.357~615  | 🍽️      |

<!-- 여기까진 그대로 둬 주세요-->

# 12.통계 기반 분석 방법론

```
✅ 학습 목표 :
* 주성분 분석(PCA)의 개념을 설명할 수 있다.
* 다중공선성을 진단할 수 있다.
* Z-TEST와 T-TEST의 개념을 비교하고, 적절한 상황에서 검정을 설계하고 수행할 수 있다.
* ANOVA TEST를 활용하여 세 개 이상의 그룹 간 평균 차이를 검정하고, 사후검정을 수행할 수 있다.
* 카이제곱 검정을 통해 범주형 변수 간의 독립성과 연관성을 분석하는 방법을 설명할 수 있다.
```

## 12.1. 분석 모델 개요

>### 1. 통계 모델 vs 기계 학습

데이터 분석 방법론은 크게 두 가지로 나뉜다.
바로 **통계학 기반의 통계 모델**과 인공지능에서 발전된 **기계 학습(Machine Learning)**이다.

| 통계 모델                | 기계 학습             |
| -------------------- | ----------------- |
| **모형화와 해석**을 중요하게 여김 | **예측 정확도 향상**에 중점 |
| 오차와 불확실성 추정을 강조      | 대용량 데이터를 기반으로 학습  |
| 해석 중심의 학문            | 성능 중심의 응용 기술      |
| 경제학적 모델링에 가까움        | 비즈니스 예측과 최적화에 강점  |

기계 학습은 통계 모델에서 출발한 개념이 많으며, 실제로 통계 모델을 이해하고 있으면 기계 학습 모델도 보다 잘 활용할 수 있다.

---

>### 2. 전통적 통계 이론 기반 분석

전통 통계 방법론은 이미 앞서 다룬 기초적 통계 이론(분포, 추정, 검정)을 기반으로 하며, 이 장에서는 다양한 변수 유형 간의 관계 분석을 중심으로 한다.

* 한 변수의 분포 → 기술통계
* 두 변수 간 관계 → 교차분석, 상관분석, 회귀분석
* 집단 간 비교 → 가설검정, 분산분석

이는 모두 통계적 가설 설정, 오차 추정, 해석을 동반하며 분석 목적은 '설명력'에 가깝다.

---

>### 3. 데이터 분석 방법론 개요

#### 📌 통계 모델 기반 분석

| 독립변수 | 종속변수 | 분석 방법론            | 용도     |
| ---- | ---- | ----------------- | ------ |
| 질적   | 질적   | 교차분석, 스피어만 서열상관분석 | 연관성 분석 |
| 질적   | 양적   | Z-test, T-test    | 가설 검정  |
| 양적   | 질적   | ANOVA, MANOVA     | 분산 분석  |
| 양적   | 양적   | 피어슨 상관분석          | 연관성 분석 |

---

### 4. 기계 학습 기반 분석

기계 학습은 **지도학습, 비지도학습, 강화학습**으로 나뉘며, 종속변수의 유무에 따라 구분된다.


#### 📌 지도학습 (Supervised Learning)

* **정답(Label)**이 있는 데이터를 학습
* 예측 또는 분류 목적

| 독립변수 | 종속변수 | 분석 방법                              | 분석 목적 |
| ---- | ---- | ---------------------------------- | ----- |
| 질적   | 질적   | 로지스틱 회귀, 분류나무, 랜덤포레스트, 나이브베이즈, 신경망 | 분류 분석 |
| 질적   | 양적   | 선형 회귀, 회귀나무, 랜덤포레스트 회귀, 신경망        | 예측 분석 |
| 양적   | 질적   | K-NN, SVM, 판별분석, 신경망 등             | 분류 분석 |
| 양적   | 양적   | 선형 회귀, 랜덤포레스트, 신경망 등               | 예측 분석 |



#### 📌 비지도학습 (Unsupervised Learning)

* **정답이 없는 데이터**에서 패턴을 찾아내는 방식
* 데이터 구조 파악, 군집화, 차원 축소 등

| 분석 기법             | 목적       |
| ----------------- | -------- |
| 주성분분석(PCA), 요인분석  | 차원 축소    |
| K-means, SOM      | 군집 분석    |
| Association Rules | 연관 규칙 도출 |

**예시**: 고객을 소득, 연령, 소비 성향에 따라 군집으로 분류하는 고객 세분화(customer segmentation)



#### 📌 강화학습 (Reinforcement Learning)

* **보상과 벌을 통해 학습**하는 방법
* 대표적으로 알파고, 게임 AI, 자율주행 등이 있다.

**핵심 개념**: 시행착오(trial & error)

* A버튼을 누르면 바나나, B버튼은 전기 충격
* 원숭이는 반복을 통해 A버튼만 누르게 됨
* 이렇게 학습되는 방식이 강화학습

| 방식             | 설명            |
| -------------- | ------------- |
| Model-free RL  | 시행착오 기반 직접 학습 |
| Model-based RL | 환경을 모델링한 후 학습 |

---

>### 5. 방법론 선택 기준 요약

* **지도학습**: 정답이 있는 데이터에서 분류·예측이 목적일 때
* **비지도학습**: 정답 없이 군집이나 패턴 발견이 목적일 때
* **강화학습**: 환경과 상호작용하며 보상 최적화를 할 때

또한, **질적/양적 변수의 조합**에 따라 사용할 수 있는 방법론이 달라지며,
하나의 방법이 여러 변수 형태에서 적용 가능한 경우도 존재한다.

예:

* 회귀 모델은 질적, 양적 독립변수 모두 사용 가능
* K-NN은 질적 종속변수 분류, 양적 종속변수 예측 모두에 사용 가능



## 12.2. 주성분 분석(PCA)

>### 1. 개념

주성분 분석(Principal Component Analysis; PCA)은 여러 개의 독립변수를 잘 설명해 줄 수 있는 핵심 성분을 추출하는 차원 축소 기법이다.
PCA는 데이터의 전체 분산을 최대한 보존하는 방향으로 새로운 축을 구성하여, 기존 고차원 데이터를 더 적은 수의 축으로 표현할 수 있게 한다.


#### 차원의 저주 (Curse of Dimensionality)

* 변수의 수(차원)가 많아지면 분석을 위한 최소한의 데이터 수도 증가한다.
* 예측은 불안정해지고, **과적합(Overfitting)** 위험도 증가한다.
* 일반적으로 차원 하나당 30개의 데이터가 필요하다.
* 예: 20개의 변수 → 600개 이상의 데이터 필요


#### 차원 축소 방법

| 방식        | 설명                                           |
| --------- | -------------------------------------------- |
| 변수 선택법    | 비교적 불필요하거나 설명력이 낮은 변수를 제거함                   |
| 잠재 성분 추출법 | 변수 간의 공통된 성분(요인)을 추출하여 변수 수를 줄임 → PCA, CFA 등 |

PCA와 공통요인분석(CFA)은 대표적인 **요인 추출 기반** 차원 축소법이며,
PCA는 정보의 손실을 최소화하는 데 집중하고, CFA는 변수 간 구조 해석에 더 중점을 둔다.



>### 2. PCA의 원리

* PCA는 데이터의 분산을 최대한 보존하는 축을 찾는 과정이다.
* 새로운 축(주성분)은 기존 변수들의 **선형 결합**으로 구성된다.
* 제1주성분은 전체 데이터 분산을 가장 잘 설명하는 축이며,
* 제2주성분은 제1주성분과 **직교(orthogonal)** 하면서 두 번째로 높은 분산을 담는다.


#### 주성분 시각적 설명

* X1, X2 두 변수의 분포를 시각화하면, 분산이 가장 넓게 퍼지는 축이 제1주성분이 된다.
* 각 점에서 주성분 축까지 수직으로 투영한 선들의 길이 제곱합이 분산이다.
* 피타고라스 정리에 따라 이 거리의 제곱합을 최대화하는 축을 찾는 것이 PCA의 핵심이다.

![alt text]()

```math
SS(x_1, x_2, ..., x_n) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}
```

* 설명력이 높은 주성분부터 차례대로 선택하여 변수 수를 축소할 수 있다.
* 대부분의 경우, **제1주성분과 제2주성분만으로 전체 분산의 상당 부분을 설명**한다.



>### 3. 실습 (Glass 데이터셋 기반)

**데이터 전처리 및 정규화**

```python
from sklearn.preprocessing import MinMaxScaler
df1 = df.drop('Type', axis=1) # 종속변수 제거
scaler = MinMaxScaler()
df_minmax = scaler.fit_transform(df1)
```

**PCA 적용**

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=9) # 최대수 9개
df_pca = pca.fit_transform(df_minmax)
```

**설명력 확인**

```python
np.round(pca.explained_variance_ratio_, 3)
```

| 주성분 | 설명력   |
| --- | ----- |
| C1  | 0.454 |
| C2  | 0.180 |
| C3  | 0.126 |
| C4  | 0.098 |
| C5  | 0.069 |
| C6  | 0.042 |
| C7  | 0.026 |
| C8  | 0.004 |
| C9  | 0.000 |

→ 총합: 100% (9개 축으로 전체 분산을 모두 설명)

**2개 축만 사용하여 시각화용 차원 축소**

```python
pca = PCA(n_components=2)
df_pca = pca.fit_transform(df_minmax)
df_pca = pd.DataFrame(df_pca, columns=['C1', 'C2'])
```

**Type 정보 결합 및 시각화**

```python
df_concat = pd.concat([df_pca, df[['Type']]], axis=1)
sns.scatterplot(data=df_concat, x='C1', y='C2', hue='Type')
```

* 전체 설명력: 약 63% (C1 + C2)
* 주성분 상에서 데이터 간 군집(클래스) 분리 여부를 시각적으로 확인 가능

---

#### 해석 및 유의점

* 주성분 분석은 **데이터 압축**, **시각화**, **모델 성능 향상** 등에 유용
* 모든 변수 간 상관관계가 높거나 다중공선성이 존재할 때 특히 효과적
* 변수 스케일이 다르면 분산 크기에 영향을 주기 때문에 **정규화 or 표준화 선행 필수**
* 단점: 각 주성분은 해석 가능한 변수 이름이 없으며, 해석력이 떨어질 수 있음




## 12.4. 다중공선성 해결과 섀플리 밸류 분석


## 12.6. Z-test와 T-test
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

## 12.7. ANOVA
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

## 12.8. 카이제곱 검정(교차분석)
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->




<br>
<br>

# 확인 문제

### **문제 1.**
> **🧚 경희는 다트비 교육 연구소의 연구원이다. 경희는 이번에 새롭게 개발한 교육 프로그램이 기존 프로그램보다 학습 성취도 향상에 효과적인지 검증하고자 100명의 학생을 무작위로 두 그룹으로 나누어 한 그룹(A)은 새로운 교육 프로그램을, 다른 그룹(B)은 기존 교육 프로그램을 수강하도록 하였다. 실험을 시작하기 전, 두 그룹(A, B)의 초기 시험 점수 평균을 비교한 결과, 유의미한 차이가 없었다. 8주 후, 학생들의 최종 시험 점수를 수집하여 두 그룹 간 평균 점수를 비교하려고 한다.**   

> **🔍 Q1. 이 실험에서 사용할 적절한 검정 방법은 무엇인가요?**

```
여기에 답을 작성해주세요!
```

> **🔍 Q2. 이 실험에서 설정해야 할 귀무가설과 대립가설을 각각 작성하세요.**

```
여기에 답을 작성해주세요!
```

> **🔍 Q3. 검정을 수행하기 위한 절차를 순서대로 서술하세요.**

<!--P.337의 실습 코드 흐름을 확인하여 데이터를 불러온 후부터 어떤 절차로 검정을 수행해야 하는지 고민해보세요.-->

```
여기에 답을 작성해주세요!
```

> **🔍 Q4. 이 검정을 수행할 때 가정해야 하는 통계적 조건을 설명하세요.**

```
여기에 답을 작성해주세요!
```

> **🔍 Q5. 추가적으로 최신 AI 기반 교육 프로그램(C)도 도입하여 기존 프로그램(B) 및 새로운 프로그램(A)과 비교하여 성취도 차이가 있는지 평가하고자 한다면 어떤 검정 방법을 사용해야 하나요? 단, 실험을 시작하기 전, C 그룹의 초기 점수 평균도 A, B 그룹과 유의미한 차이가 없었다고 가정한다.**

```
여기에 답을 작성해주세요!
```

> **🔍 Q6. 5번에서 답한 검정을 수행한 결과, 유의미한 차이가 나타났다면 추가적으로 어떤 검정을 수행해 볼 수 있을까요?**

```
여기에 답을 작성해주세요!
```

---

### **문제 2. 카이제곱 검정**  
> **🧚 다음 중 어떠한 경우에 카이제곱 검정을 사용해야 하나요?   
1️⃣ 제품 A, B, C의 평균 매출 차이를 비교하고자 한다.  
2️⃣ 남성과 여성의 신체 건강 점수 평균 차이를 분석한다.  
3️⃣ 제품 구매 여부(구매/미구매)와 고객의 연령대(10대, 20대, 30대…) 간의 연관성을 분석한다.  
4️⃣ 특정 치료법이 환자의 혈압을 감소시키는 효과가 있는지 확인한다.**  

```
여기에 답을 작성해주세요!
```

### 🎉 수고하셨습니다.