# 통계학 4주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_4th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

4주차는 `2부. 데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_4th_TIL

### 2부. 데이터 분석 준비하기
### 10. 데이터 탐색과 시각화



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | 🍽️      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      | 

<!-- 여기까진 그대로 둬 주세요-->

# 10. 데이터 탐색과 시각화

```
✅ 학습 목표 :
* EDA의 목적을 설명할 수 있다.
* 주어진 데이터셋에서 이상치, 누락값, 분포 등을 식별하고 EDA 결과를 바탕으로 데이터셋의 특징을 해석할 수 있다.
* 공분산과 상관계수를 활용하여 두 변수 간의 관계를 해석할 수 있다.
* 적절한 시각화 기법을 선택하여 데이터의 특성을 효과적으로 전달할 수 있다.
```
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

알겠다. 아래는 **10.1부터 10.8까지 전체 완성본**이야. 복사해서 바로 붙여넣으면 돼. 마크다운 형식, 수식, 코드, 불릿 다 통일해서 정리했다.

---

> ### 10.1 탐색적 데이터 분석

* **EDA와 데이터 시각화**: EDA 단계에서 데이터를 파악하기 위해 시각화를 활용하지만, 시각화의 궁극적인 목적은 분석 결과를 명확히 전달하는 데 있다.

* **EDA의 주요 목적**

  * 데이터 형태와 척도가 분석에 적합한지 확인 (sanity checking)
  * 평균·분산·분포·패턴 등 기초 통계 확인을 통해 데이터 특성 파악
  * 결측치 및 이상치 탐지·보완
  * 변수 간 관계성 파악
  * 분석 목적과 방향성 점검 및 보정

> ### 10.1.1 엑셀을 활용한 EDA

* 1,000개 샘플을 단순 임의추출해 빠르게 데이터 전반을 파악할 수 있다.
* 소규모 데이터라면 엑셀이 가장 직관적이고 효율적이다.

> ### 10.1.2 탐색적 데이터 분석 실습

* **기초 통계량 확인**

```python
df.head()
df.info()
df.describe()
df.skew()
df.kurtosis()
```

* **시각화**

```python
sns.distplot(df['lead_time'])
sns.violinplot(x='hotel', y='lead_time', data=df, inner=None, color='.8')
sns.stripplot(x='hotel', y='lead_time', data=df, size=1)
```

---

> ### 10.2 공분산과 상관성 분석

* 목표 변수뿐 아니라 입력 변수 간 관계도 함께 점검해야 한다.

> #### 10.2.1 공분산

* 두 확률 변수 X,Y의 선형 동조 정도를 나타낸다.
* 정의식

  $$
  \{Cov}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{X})(y_i - \bar{Y})
  $$
* 양수 → 같은 방향, 음수 → 반대 방향, 0 → 무관. 단위의 영향을 받아 비교 불가.

> #### 10.2.2 상관계수

* 피어슨 상관계수: X,Y의 공분산의 각각의 표준편차로 나눈 것으로 표준화된 공분산. 두 변수간 선형성을 측정
* 
* 경험적 기준:

  * r >+ 0.7 → 강한 상관  
    
  * r >= 0.4 → 중간 상관  
    

* 이상치에 민감, 선형성만 측정함에 주의.

* **척도별 상관계수 방법**

| 방법             | 데이터 척도 조합        |
| -------------- | ---------------- |
| Pearson        | 간격/비율 – 간격/비율    |
| Spearman       | 서열 – 서열          |
| Point–biserial | 간격/비율 – 명목(2분)   |
| Phi            | 명목(2분) – 명목(2분)  |
| Cramer’s V     | 명목 – 명목 (2×2 이상) |

> #### 10.2.3 공분산과 상관성 분석 실습

```python
sns.pairplot(df, diag_kind='kde')
df.cov()
df.corr(method='pearson')
sns.heatmap(df.corr(), cmap='viridis')
sns.clustermap(df.corr(), annot=True, cmap='RdYlBu_r', vmin=-1, vmax=1)

mask = np.triu(np.ones_like(df.corr(), dtype=bool))
fig, ax = plt.subplots(figsize=(15, 10))
sns.heatmap(df.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='RdYlBu_r', cbar=True)
ax.set_title('Wine Quality Correlation', pad=15)
```

---

> ### 10.3 시간 시각화

* 선 그래프: 시간 간격이 촘촘할 때
* 막대/누적 막대: 시간 밀도가 낮을 때
* 이동평균:

$$
{\text{MA}_t^{(k)} = \frac{1}{k} \sum_{i=0}^{k-1} y_{t-i}}
$$


> #### 10.3.1 시간 시각화 실습

```python
df['Date2'] = pd.to_datetime(df['Order Date'], infer_datetime_format=True)
df = df.sort_values('Date2')
df['Year'] = df['Date2'].dt.year

df_line = df[df.Year == 2018].groupby('Date2')['Sales'].sum().reset_index()
df_line['MA30'] = df_line['Sales'].rolling(window=30).mean()

ax = df_line.plot(x='Date2', y='Sales', linewidth=0.5)
df_line.plot(x='Date2', y='MA30', color='#FF7F50', linewidth=1, ax=ax)

df.groupby('Year')['Sales'].sum().plot.bar(rot=0, figsize=(10,5))
pivot = df.groupby(['Year','Segment'])['Sales'].sum().unstack()
pivot.plot.bar(stacked=True, figsize=(10,7))
```

---

> ### 10.4 비교 시각화

* **히트맵**: 그룹 내 변수 간 비교
* **방사형 차트**: 그룹별 특성 시각화
* **평행 좌표 그래프**: 변수별 분포 비교에 유리

> #### 10.4.1 비교 시각화 실습

```python
from math import pi
from pandas.plotting import parallel_coordinates

# 히트맵
df1 = df[df['Tm'].isin(['ATL','BOS','BRK','CHI','CHO'])][['Tm','ORB%','TRB%','AST%','BLK%','USG%']].groupby('Tm').mean()
plt.figure(figsize=(8,8)); plt.pcolor(df1.values)
plt.xticks(range(len(df1.columns)), df1.columns)
plt.yticks(range(len(df1.index)), df1.index)
plt.colorbar(); plt.show()

# 방사형 차트
df3 = df1.reset_index()
labels = df3.columns[1:]
angles = [n / float(len(labels)) * 2 * pi for n in range(len(labels))] + [0]
palette = plt.cm.get_cmap('Set2', len(df3))
fig = plt.figure(figsize=(15,20))
for i, row in df3.iterrows():
    ax = plt.subplot(3,2,i+1, polar=True)
    data = row.drop('Tm').tolist() + [row[1]]
    ax.plot(angles, data, color=palette(i))
    ax.fill(angles, data, color=palette(i), alpha=0.2)
    plt.xticks(angles[:-1], labels)
    plt.title(row.Tm, y=1.15)
plt.tight_layout(); plt.show()

# 평행 좌표
plt.figure(figsize=(16,8))
parallel_coordinates(df3, 'Tm', colormap='winter')
plt.show()
```

---

> ### 10.5 분포 시각화

* 연속형: 히스토그램, 선, 막대
* 명목형: 파이, 도넛, 트리맵, 와플 차트

> #### 10.5.1 분포 시각화 실습

```python
df1 = df[['height_cm']]
plt.hist(df1, bins=10)
plt.show()

df1_m = df[df['sex'] == 'man'][['height_cm']]
df1_w = df[df['sex'] == 'woman'][['height_cm']]
plt.hist(df1_m, color='green', alpha=0.2, bins=10, label='MAN', density=True)
plt.hist(df1_w, color='red', alpha=0.2, bins=10, label='WOMAN', density=True)
plt.legend(); plt.show()

df2 = df[df.height_cm >= 175].groupby('country').count().reset_index()

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot()
ax.pie(df2.height_cm, labels=df2.country, autopct='%1.1f%%')
plt.legend(); plt.show()

wedgeprops = {'width': 0.7, 'edgecolor': 'w', 'linewidth': 5}
plt.pie(df2.height_cm, labels=df2.country, autopct='%.1f%%', wedgeprops=wedgeprops)
plt.show()

df3 = df[df.height_cm >= 175].groupby(['country','sex']).count().reset_index()
fig = px.treemap(df3, path=['sex','country'], values='height_cm', color='height_cm', color_continuous_scale='viridis')
fig.show()

fig = plt.figure(FigureClass=Waffle, rows=10, figsize=(10,10), plots={
    111: {
        'values': df2['height_cm'],
        'labels': [f\"{c} ({v})\" for c,v in df2['country'].items()],
        'legend': {'loc': 'upper left', 'bbox_to_anchor': (1.05, 1), 'fontsize': 8},
        'title': {'label': 'Waffle chart test', 'loc': 'left'}
    }
})
```

---

> ### 10.6 관계 시각화

* 산점도: 변수 간 연속 관계 표현
* 버블차트: 세 변수 시각화 (x, y, 크기)

> #### 10.6.1 관계 시각화 실습

```python
plt.scatter(df['R&D Spend'], df['Profit'], s=50, alpha=0.4)
plt.show()

sns.lmplot(x='R&D Spend', y='Profit', data=df)

plt.scatter(df['R&D Spend'], df['Profit'],
            s=df['Marketing Spend'] * 0.001,
            c=df['Administration'], alpha=0.5, cmap='Spectral')
plt.colorbar(); plt.show()
```

---

> ### 10.7 공간 시각화

* 지도 위에 분포 표현. 도트, 버블, 코로플레스, 커넥션맵 활용

> #### 10.7.1 공간 시각화 실습

```python
m = folium.Map(location=[37.541, 126.986], zoom_start=12)
cluster = plugins.MarkerCluster(locations=list(zip(df.latitude, df.longitude)), popups=df['name'].tolist())
m.add_child(cluster)

df_m = df.groupby('gu_name').agg({'latitude':'mean','longitude':'mean','name':'count'}).reset_index()
m = folium.Map(location=[37.541, 126.986], tiles='Cartodb Positron', zoom_start=11)
for i, row in df_m.iterrows():
    folium.CircleMarker(location=[row.latitude, row.longitude], radius=row.name/2, fill_color='blue').add_to(m)

m = folium.Map(location=[40,-98], zoom_start=3, tiles='Cartodb Positron')
m.choropleth(geo_data=us_geo, data=df2, columns=['State','Unemployment'], key_on='feature.id',
             fill_color='YlGn', legend_name='실업률')

fig = go.Figure()
coords = zip([37.541]*5, [35.6804, 38.9072, 14.5995, 48.8566, 55.7558], [126.986]*5, [139.7690, -77.0369, 120.9842, 2.3522, 37.6173])
for a, b, c, d in coords:
    fig.add_trace(go.Scattergeo(lat=[a, b], lon=[c, d], mode='lines', line=dict(width=1, color='red'), opacity=0.5))
fig.update_layout(margin=dict(t=0, b=0, l=0, r=0), showlegend=False, geo=dict(showcountries=True))
fig.show()
```

---

> ### 10.8 박스 플롯

* 다중 그룹 간 분포·중앙값·편향성 확인에 유용
* 구성: 최소, Q1, Q2(중앙), Q3, 최대값

> #### 10.8.1 박스 플롯 실습

```python
plt.figure(figsize=(8, 6))
sns.boxplot(y='Profit', data=df)
plt.show()

plt.figure(figsize=(8, 2))
sns.boxplot(x='Profit', data=df)
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x='State', y='Profit', data=df)
plt.show()

sns.boxplot(x='State', y='Profit', showmeans=True, boxprops={'facecolor':'None'}, data=df)
sns.stripplot(x='State', y='Profit', data=df, jitter=True, marker='o', alpha=0.5, color='black')
plt.show()
```

---




<br>
<br>

# 확인 문제

## 문제 1.
> **🧚 공분산과 상관계수의 차이점에 대해 간단히 설명하세요.**

```
 공분산(Covariance)은 두 확률 변수 간의 선형 관계의 방향을 나타낸다. 즉, 두 변수가 함께 증가하거나 감소하는 경향이 있는지를 평가하며, 양수면 정비례, 음수면 반비례 관계를 의미한다.
 
 그러나 공분산의 크기는 변수들의 단위(scale)에 의존하므로, 서로 다른 단위의 변수 간 공분산 값을 직접 비교하거나 상관의 강도를 평가하는 데는 적합하지 않다.

 이를 극복하기 위해 공분산을 각 변수의 표준편차로 나누어 단위에 관계없이 해석 가능하도록 표준화한 지표가 상관계수다.

 상관계수는 일반적으로 피어슨 상관계수를 의미하며, 이는 선형 상관관계만 측정한다. 즉, 비선형 관계가 존재하더라도 상관계수가 0에 가까울 수 있다. 또한 이상치에 매우 민감하므로 해석 시 주의가 필요하다.
```

## 문제 2.
> **🧚 다음 데이터 분석 목표에 적합한 시각화 방법을 보기에서 모두 골라 연결해주세요.**

> 보기: 산점도, 선그래프, 막대그래프, 히스토그램, 박스플롯

(a) 변수의 분포 확인   
(b) 두 변수 간의 관계 확인   
(c) 집단별 평균 비교   
(d) 시계열 데이터 분석

<!--중복 가능-->

```
(a) 히스토그램, 박스플롯
(b) 산점도
(c) 박스플롯
(d) 선 그래프, 막대그래프
```


### 🎉 수고하셨습니다.
